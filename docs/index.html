<!DOCTYPE html>
<meta charset="utf-8">
<html>
<style type="text/css">
body {
    font-family: "Titillium Web", "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
    font-weight: 300;
    font-size: 17px;
    margin-left: auto;
    margin-right: auto;
    width: 980px;
}
h1 {
    font-weight:300;
    line-height: 1.15em;
}

h2 {
    font-size: 1.75em;
}
a:link,a:visited {
    color: #1367a7;
    text-decoration: none;
}
a:hover {
    color: #208799;
}
h1, h2, h3 {
    text-align: center;
}
h1 {
    font-size: 40px;
    font-weight: 500;
}
h2, h3 {
    font-weight: 400;
    margin: 16px 0px 4px 0px;
}
.paper-title {
    padding: 16px 0px 16px 0px;
}
section {
    margin: 32px 0px 32px 0px;
    text-align: justify;
    clear: both;
}
.col-5 {
     width: 20%;
     float: left;
}
.col-4 {
     width: 25%;
     float: left;
}
.col-3 {
     width: 33%;
     float: left;
}
.col-2 {
     width: 50%;
     float: left;
}
.row, .author-row, .affil-row {
     overflow: auto;
}
.author-row, .affil-row {
    font-size: 20px;
}
.row {
    margin: 16px 0px 16px 0px;
}
.authors {
    font-size: 18px;
}
.affil-row {
    margin-top: 16px;
}
.teaser {
    max-width: 100%;
}
.text-center {
    text-align: center;
}
.screenshot {
    width: 256px;
    border: 1px solid #ddd;
}
.screenshot-lg {
    width: 512px;
    border: 1px solid #ddd;
    display: block;
    margin-left: auto;
    margin-right: auto;
}
.screenshot-elg {
    width: 100%;
    border: 1px solid #ddd;
    display: block;
    margin-left: auto;
    margin-right: auto;
}
.screenshot-el {
    margin-bottom: 16px;
}
hr {
    height: 1px;
    border: 0;
    border-top: 1px solid #ddd;
    margin: 0;
}
.material-icons {
    vertical-align: -6px;
}
p {
    line-height: 1.25em;
}
.caption_justify {
    font-size: 16px;
    /*font-style: italic;*/
    color: #666;
    text-align: justify;
    margin-top: 0px;
    margin-bottom: 64px;
}
.caption {
    font-size: 16px;
    /*font-style: italic;*/
    color: #666;
    text-align: center;
    margin-top: 8px;
    margin-bottom: 64px;
}
.caption_inline {
    font-size: 16px;
    /*font-style: italic;*/
    color: #666;
    text-align: center;
    margin-top: 8px;
    margin-bottom: 0px;
}
.caption_bold {
    font-size: 16px;
    /*font-style: italic;*/
    color: #666;
    text-align: center;
    margin-top: 0px;
    margin-bottom: 0px;
    font-weight: bold;
}
video {
    display: block;
    margin: auto;
}
figure {
    display: block;
    margin: auto;
    margin-top: 10px;
    margin-bottom: 10px;
}
figure {
    display: block;
    margin: auto;
    margin-top: 10px;
    margin-bottom: 10px;
}
#bibtex pre {
    font-size: 14px;
    background-color: #eee;
    padding: 16px;
}
.blue {
    color: #2c82c9;
    font-weight: bold;
}
.orange {
    color: #d35400;
    font-weight: bold;
}
.flex-row {
    display: flex;
    flex-flow: row wrap;
    justify-content: space-around;
    padding: 0;
    margin: 0;
    list-style: none;
}
.paper-btn {
  position: relative;
  text-align: center;

  display: inline-block;
  margin: 8px;
  padding: 8px 8px;

  border-width: 0;
  outline: none;
  border-radius: 2px;

  background-color: #1367a7;
  color: #ecf0f1 !important;
  font-size: 20px;
  width: 100px;
  font-weight: 600;
}
.paper-btn-parent {
    display: flex;
    justify-content: center;
    margin: 16px 0px;
}
.paper-btn:hover {
    opacity: 0.85;
}
.container {
    margin-left: auto;
    margin-right: auto;
    padding-left: 16px;
    padding-right: 16px;
}
.venue {
    color: #1367a7;
}
</style>
<link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <meta name="google-site-verification" content="FxvrYx4mHxCIZntr6Xi_SBt8ZTkG_EJRubp1bTN307E"/>
    
    <title>Towards Understanding 3D Vision: the Role of Gaussian Curvature</title>
    <meta name="description" content="Towards Understanding 3D Vision: the Role of Gaussian Curvature.">
    
     <!-- SEO -->
    <meta name="robots" content="index, follow">
    <link rel="canonical" href="https://sherlonalmeida.github.io/gaussian-curvature-in-3D-vision/">
    
    <!-- OpenGraph -->
    <meta property="og:description" content="Towards Understanding 3D Vision: the Role of Gaussian Curvature"/>
    <meta property="og:abreviation" content="Gaussian-Curvature-in-3D-Vision"/>
    <meta property="og:url" content="https://sherlonalmeida.github.io/gaussian-curvature-in-3D-vision/">
    <meta property="og:type" content="website">
    <meta property="og:image" itemprop="image" content="https://sherlonalmeida.github.io/gaussian-curvature-in-3D-vision/blob/master/docs/assets/gauss_curv_thumbnail.png">
    <link href="https://fonts.googleapis.com/css2?family=Material+Icons" rel="stylesheet">

    <!-- Twitter --> 
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:creator" content="@SherlonAlmeida">
    <meta name="twitter:title" content="Towards Understanding 3D Vision: the Role of Gaussian Curvature">
    <meta name="twitter:description" content="Towards Understanding 3D Vision: the Role of Gaussian Curvature.">
    <meta name="twitter:image" content="https://sherlonalmeida.github.io/gaussian-curvature-in-3D-vision/blob/master/docs/assets/gauss_curv_thumbnail.png">
</head>


<body>
<div class="container">
    <div class="paper-title">
        <h1>Towards Understanding 3D Vision: the Role of Gaussian Curvature</h1>
    </div>

    <div id="authors">
        <div class="author-row">
            <div class="col-4 text-center"><a href="https://www.linkedin.com/in/sherlonalmeida/">Sherlon Almeida da Silva</a><sup>1, 2*</sup></div>
            <div class="col-4 text-center"><a href="https://cs.nyu.edu/~geiger/">Davi Geiger</a><sup>2</sup></div>
            <div class="col-4 text-center"><a href="https://lvelho.impa.br/">Luiz Velho</a><sup>3</sup></div>
            <div class="col-4 text-center"><a href="https://sites.google.com/site/moacirponti/">Moacir Antonelli Ponti</a><sup>1</sup></div>
        </div>

        <div class="affil-row">
            <div class="col-3 text-center"><sup>1</sup>ICMC-USP</div>
            <div class="col-3 text-center"><sup>2</sup>COURANT-NYU</div>
            <div class="col-3 text-center"><sup>3</sup>IMPA</div>
        </div>

        <div style="clear: both">
            <div class="paper-btn-parent">
                <a class="paper-btn" href="assets/pre_print-towards_understanding_3d_vision_the_role_of_gaussian_curvature.pdf">
                    <span class="material-icons"> description </span>
                    Paper
                </a>
                <a class="paper-btn" href="https://github.com/SherlonAlmeida/gaussian-curvature-in-3D-vision">
                    <span class="material-icons"> code </span>
                    Code
                </a>
                <!-- <a class="paper-btn" href="https://sherlonalmeida.github.io/gaussian-curvature-in-3D-vision/blob/master/demo/GaussianCurvature-Demo.ipynb">
                    <span class="material-icons"> code </span>
                    Demo
                </a> -->
            </div>
        </div>
    </div>

    <section id="abstract">
        <h2>Abstract</h2>
        <hr>
    <p>
        Recent advances in computer vision have predominantly relied on data-driven approaches that leverage deep learning and large-scale datasets. Deep neural networks have achieved remarkable success in tasks such as stereo matching and monocular depth reconstruction. However, these methods lack explicit models of 3D geometry that can be directly analyzed, transferred across modalities, or systematically modified for controlled experimentation. We investigate the role of Gaussian curvature in 3D surface modeling. Besides Gaussian curvature being an invariant quantity under change of observers or coordinate systems, we demonstrate using the Middlebury stereo dataset that it offers a sparse and compact description of 3D surfaces. Furthermore, we show a strong correlation between the performance rank of top state-of-the-art stereo and monocular methods and the low total absolute Gaussian curvature. We propose that this property can serve as a geometric prior to improve future 3D reconstruction algorithms.
    </p>
    </section>

    <section id="teaser-videos">
        <!--
        <figure style="width: 60%; float: center">
            <img class="screenshot-elg" src="assets/teaser.jpg">
        </figure>
        -->

    </section>

    <section id="overview">
        <h2>Overview</h2>
        <hr>
        <p>
            <figure style="width: 100%; float: center">
            <p  style="text-align:justify;">
            In this paper we study the importance of the Gaussian curvature in 3D vision, presenting an analysis on 3D reconstruction provided by stereo algorithms on the Middlebury benchmark.
            We observed that the best techniques tend to reconstruct surfaces with low Gaussian curvature and more consistent normals. See some experiments below:
            </p>

            <img class="screenshot-elg" src="assets/curvature_metrics.png">
            <p style="text-align:center">
            This table presents the Middlebury benchmark ranking for the 15 training images, with techniques listed in descending LGC order. Superscripts indicate each methodâ€™s rank among the compared techniques for the metrics AvgError, RMS, Bad 2.0, and Bad 4.0. Darker cell shading highlights better performance, indicating the technique is among the Top 1, Top 3, or Top 5 best approaches. Notably, top-performing methods (Group A) generally exhibit higher LGC (i.e., lower GC).
            </p>

            <img class="screenshot-elg" src="assets/curvature.png">
            <p style="text-align:center">
            GT x SOTA approaches: a point-wise analysis of curvature for "Piano" image. Black coordinates represent values of $|K| > 1{,}000m^{-2}$. For the GT, black coordinates also represent NaN values, which are measurement inconsistencies during Middlebury disparity estimation. In the second row, we applied smoothing with $\sigma = 2\, m$ in the 3D point cloud before computing the GC.
            Interpretation: Foundation-Stereo estimates lower Gaussian curvature than Selective-IGEV.
            </p>

            <img class="screenshot-elg" src="assets/normals_metrics.png">
            <p style="text-align:center">
            This table presents techniques listed in ascending Normal Average Error (NormAvg) order for the 15 Middlebury training images. Superscripts indicate the lowest 1-5th Normal Error (NormalsErr) per technique for each one of the 15 Middlebury images. Darker cell shading highlights lower NormalsErr, indicating the technique is among the Top 1, Top 3, or Top 5 approaches with the lowest NormalsErr. Notably, the top-performing methods are from the Group A, and predict surface normals that are closely aligned with the ground truth.
            </p>

            <img class="screenshot-elg" src="assets/normals.png">
            <p style="text-align:center">
            Normals Analysis: Qualitative comparison on normals reconstruction for Piano data.
            Interpretation: Selective-IGEV reconstructs noisier surfaces, while Foundation-Stereo and BLMT-Stereo present consistent normals. Also, BLMT-Stereo has sharper results near the edges (depth discontinuities).
            </p>

            <p  style="text-align:justify;">
                In summary, our work enhances the interpretability and understanding of 3D vision by highlighting Gaussian Curvature as an intrinsic geometric prior for indoor 3D surfaces. Grounded in modern deep learning data, our approach underscores the importance of 3D geometric modeling in capturing critical visual information and can guide the development of next-generation vision systems.
            </p>
        </figure>
        </p>
    </section>

    <section id="paper">
        <h2>Paper</h2>
        <hr>
        <div class="flex-row">
            <div style="box-sizing: border-box; padding: 16px; margin: auto;">
                <a href="assets/pre_print-towards_understanding_3d_vision_the_role_of_gaussian_curvature.pdf"><img class="screenshot" src="assets/gauss_curv_thumbnail.png"></a>
            </div>
            <div style="width: 60%">
                <p><b>Towards Understanding 3D Vision: the Role of Gaussian Curvature</b></p>
                <p>Sherlon Almeida da Silva, Davi Geiger, Luiz Velho, and Moacir Antonelli Ponti</p>

                <div><span class="material-icons"> description </span><a href="assets/pre_print-towards_understanding_3d_vision_the_role_of_gaussian_curvature.pdf"> Paper preprint (PDF, 12 MB)</a></div>
                <div><span class="material-icons"> description </span><a href="https://arxiv.org/abs/2508.11825"> arXiv version</a></div>
                <!-- <div><span class="material-icons"> image </span><a href="assets/TUNER-CVPR-poster.pdf"> Poster</a></div> -->
                <!-- <div><span class="material-icons"> insert_comment </span><a href="assets/novello2025tuning.bib"> BibTeX</a></div>  -->
                <!-- <div><span class="material-icons"> videocam </span><a href=""> Soon</a></div> -->

                <p>If you have any questions, please reach out to <a href="https://scholar.google.com.br/citations?user=boFxo4gAAAAJ&hl">Sherlon Almeida</a>: sherlon@usp.br.</p>
            </div>
        </div>
    </section>

    <section id="bibtex">
            <h2>Citation</h2>
            <hr>
            <pre><code>@inproceedings{dasilva2026gausscurv,
    title={Towards Understanding 3D Vision: the Role of Gaussian Curvature},
    author={da Silva, Sherlon Almeida and Geiger, Davi and Velho, Luiz and Ponti, Moacir Antonelli},
    booktitle={21st International Conference on Computer Vision Theory and Applications},
    year={2026},
    organization={SCITEPRESS}
}
            </code></pre>
    </section>
</div>
</body>

</html>
